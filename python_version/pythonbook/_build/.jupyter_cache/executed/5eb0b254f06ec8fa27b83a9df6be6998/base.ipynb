{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03f2f2d8",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    Distance       Elapsed (seconds)\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25           4.104e-01      1.683e+00         \n",
      "50           2.102e-01      1.734e+00         \n",
      "75           9.558e-02      1.784e+00         \n",
      "100          5.715e-02      1.816e+00         \n",
      "125          3.436e-02      1.862e+00         \n",
      "150          2.070e-02      1.894e+00         \n",
      "175          1.249e-02      1.925e+00         \n",
      "200          7.532e-03      1.958e+00         \n",
      "225          4.545e-03      1.988e+00         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250          2.743e-03      2.019e+00         \n",
      "275          1.655e-03      2.068e+00         \n",
      "300          9.987e-04      2.106e+00         \n",
      "325          6.027e-04      2.147e+00         \n",
      "350          3.637e-04      2.186e+00         \n",
      "375          2.195e-04      2.233e+00         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400          1.324e-04      2.258e+00         \n",
      "425          7.993e-05      2.302e+00         \n",
      "450          4.823e-05      2.334e+00         \n",
      "475          2.911e-05      2.365e+00         \n",
      "500          1.757e-05      2.397e+00         \n",
      "525          1.060e-05      2.428e+00         \n",
      "528          9.977e-06      2.444e+00         \n",
      "Converged in 528 steps\n"
     ]
    }
   ],
   "source": [
    "from quantecon import compute_fixed_point\n",
    "\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from numba import njit\n",
    "\n",
    "\n",
    "# NamedTuple Model\n",
    "Model = namedtuple(\"Model\", (\"β\", \"K\", \"c\", \"κ\", \"p\"))\n",
    "\n",
    "\n",
    "def create_inventory_model(β=0.98,      # discount factor\n",
    "                           K=40,        # maximum inventory\n",
    "                           c=0.2, κ=2,  # cost parameters\n",
    "                           p=0.6):      # demand parameter\n",
    "    return Model(β=β, K=K, c=c, κ=κ, p=p)\n",
    "\n",
    "\n",
    "@njit\n",
    "def demand_pdf(d, p):\n",
    "    return (1 - p)**d * p\n",
    "\n",
    "\n",
    "@njit\n",
    "def B(x, a, v, model, d_max=101):\n",
    "    \"\"\"\n",
    "    The function B(x, a, v) = r(x, a) + β Σ_x′ v(x′) P(x, a, x′).\n",
    "    \"\"\"\n",
    "    β, K, c, κ, p = model\n",
    "    x1 = np.array([np.minimum(x, d)*demand_pdf(d, p) for d in np.arange(d_max)])\n",
    "    reward = np.sum(x1) - c * a - κ * (a > 0)\n",
    "    x2 = np.array([v[np.maximum(0, x - d) + a] * demand_pdf(d, p)\n",
    "                                 for d in np.arange(d_max)])\n",
    "    continuation_value = β * np.sum(x2)\n",
    "    return reward + continuation_value\n",
    "\n",
    "\n",
    "@njit\n",
    "def T(v, model):\n",
    "    \"\"\"The Bellman operator.\"\"\"\n",
    "    β, K, c, κ, p = model\n",
    "    new_v = np.empty_like(v)\n",
    "    for x in range(0, K+1):\n",
    "        x1 = np.array([B(x, a, v, model) for a in np.arange(K-x+1)])\n",
    "        new_v[x] = np.max(x1)\n",
    "    return new_v\n",
    "\n",
    "\n",
    "@njit\n",
    "def get_greedy(v, model):\n",
    "    \"\"\"\n",
    "    Get a v-greedy policy.  Returns a zero-based array.\n",
    "    \"\"\"\n",
    "    β, K, c, κ, p = model\n",
    "    σ_star = np.zeros(K+1, dtype=np.int32)\n",
    "    for x in range(0, K+1):\n",
    "        x1 = np.array([B(x, a, v, model) for a in np.arange(K-x+1)])\n",
    "        σ_star[x] = np.argmax(x1)\n",
    "    return σ_star\n",
    "\n",
    "\n",
    "def solve_inventory_model(v_init, model):\n",
    "    \"\"\"Use successive_approx to get v_star and then compute greedy.\"\"\"\n",
    "    β, K, c, κ, p = model\n",
    "    v_star = compute_fixed_point(lambda v: T(v, model), v_init,\n",
    "                                 error_tol=1e-5, max_iter=1000, print_skip=25)\n",
    "    σ_star = get_greedy(v_star, model)\n",
    "    return v_star, σ_star\n",
    "\n",
    "\n",
    "# == Plots == #\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Create an instance of the model and solve it\n",
    "model = create_inventory_model()\n",
    "β, K, c, κ, p = model\n",
    "v_init = np.zeros(K+1)\n",
    "v_star, σ_star = solve_inventory_model(v_init, model)\n",
    "\n",
    "\n",
    "def sim_inventories(ts_length=400, X_init=0):\n",
    "    \"\"\"Simulate given the optimal policy.\"\"\"\n",
    "    global p, σ_star\n",
    "    X = np.zeros(ts_length, dtype=np.int32)\n",
    "    X[0] = X_init\n",
    "    # Subtracts 1 because numpy generates only positive integers\n",
    "    rand = np.random.default_rng().geometric(p=p, size=ts_length-1) - 1\n",
    "    for t in range(0, ts_length-1):\n",
    "        X[t+1] = np.maximum(X[t] - rand[t], 0) + σ_star[X[t] + 1]\n",
    "    return X\n",
    "\n",
    "\n",
    "def plot_vstar_and_opt_policy(fontsize=10,\n",
    "                   figname=\"../figures/inventory_dp_vs.pdf\",\n",
    "                   savefig=False):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(8, 6.5))\n",
    "\n",
    "    ax = axes[0]\n",
    "    ax.plot(np.arange(K+1), v_star, label=r\"$v^*$\")\n",
    "    ax.set_ylabel(\"value\", fontsize=fontsize)\n",
    "    ax.legend(fontsize=fontsize, frameon=False)\n",
    "\n",
    "    ax = axes[1]\n",
    "    ax.plot(np.arange(K+1), σ_star, label=r\"$\\sigma^*$\")\n",
    "    ax.set_xlabel(\"inventory\", fontsize=fontsize)\n",
    "    ax.set_ylabel(\"optimal choice\", fontsize=fontsize)\n",
    "    ax.legend(fontsize=fontsize, frameon=False)\n",
    "    if savefig:\n",
    "        fig.savefig(figname)\n",
    "\n",
    "\n",
    "def plot_ts(fontsize=10,\n",
    "            figname=\"../figures/inventory_dp_ts.pdf\",\n",
    "            savefig=False):\n",
    "    X = sim_inventories()\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.5))\n",
    "    ax.plot(X, label=\"$X_t$\", alpha=0.7)\n",
    "    ax.set_xlabel(\"$t$\", fontsize=fontsize)\n",
    "    ax.set_ylabel(\"inventory\", fontsize=fontsize)\n",
    "    ax.legend(fontsize=fontsize, frameon=False)\n",
    "    ax.set_ylim(0, np.max(X)+4)\n",
    "    if savefig:\n",
    "        fig.savefig(figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19513453",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_vstar_and_opt_policy(savefig\u001b[38;5;241m=\u001b[39m\u001b[43mtrue\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'true' is not defined"
     ]
    }
   ],
   "source": [
    "plot_vstar_and_opt_policy(savefig=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8688cbda",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_ts(savefig\u001b[38;5;241m=\u001b[39m\u001b[43mtrue\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'true' is not defined"
     ]
    }
   ],
   "source": [
    "plot_ts(savefig=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dda2e42d",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from quantecon.markov import tauchen\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from numba import njit, prange\n",
    "\n",
    "\n",
    "# NamedTuple Model\n",
    "Model = namedtuple(\"Model\", (\"β\", \"R\", \"γ\", \"w_grid\", \"y_grid\", \"Q\"))\n",
    "\n",
    "\n",
    "def create_savings_model(R=1.01, β=0.98, γ=2.5,\n",
    "                         w_min=0.01, w_max=20.0, w_size=200,\n",
    "                         ρ=0.9, ν=0.1, y_size=5):\n",
    "    w_grid = np.linspace(w_min, w_max, w_size)\n",
    "    mc = tauchen(ρ, ν, n=y_size)\n",
    "    y_grid, Q = np.exp(mc.state_values), mc.P\n",
    "    return Model(β=β, R=R, γ=γ, w_grid=w_grid, y_grid=y_grid, Q=Q)\n",
    "\n",
    "\n",
    "@njit\n",
    "def U(c, γ):\n",
    "    return c**(1-γ)/(1-γ)\n",
    "\n",
    "\n",
    "@njit\n",
    "def B(i, j, k, v, model):\n",
    "    \"\"\"\n",
    "    B(w, y, w′, v) = u(R*w + y - w′) + β Σ_y′ v(w′, y′) Q(y, y′).\n",
    "    \"\"\"\n",
    "    β, R, γ, w_grid, y_grid, Q = model\n",
    "    w, y, w_1 = w_grid[i], y_grid[j], w_grid[k]\n",
    "    c = w + y - (w_1 / R)\n",
    "    value = -np.inf\n",
    "    if c > 0:\n",
    "        value = U(c, γ) + β * np.dot(v[k, :], Q[j, :])\n",
    "    return value\n",
    "\n",
    "\n",
    "@njit(parallel=True)\n",
    "def T(v, model):\n",
    "    \"\"\"The Bellman operator.\"\"\"\n",
    "    β, R, γ, w_grid, y_grid, Q = model\n",
    "    v_new = np.empty_like(v)\n",
    "    for i in prange(w_grid.shape[0]):\n",
    "        for j in prange(y_grid.shape[0]):\n",
    "            x_tmp = np.array([B(i, j, k, v, model) for k\n",
    "                              in np.arange(w_grid.shape[0])])\n",
    "            v_new[i, j] = np.max(x_tmp)\n",
    "    return v_new\n",
    "\n",
    "\n",
    "@njit(parallel=True)\n",
    "def T_σ(v, σ, model):\n",
    "    \"\"\"The policy operator.\"\"\"\n",
    "    β, R, γ, w_grid, y_grid, Q = model\n",
    "    v_new = np.empty_like(v)\n",
    "    for i in prange(w_grid.shape[0]):\n",
    "        for j in prange(y_grid.shape[0]):\n",
    "            v_new[i, j] = B(i, j, σ[i, j], v, model)\n",
    "    return v_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "833951ee",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from finite_opt_saving_0 import U, B\n",
    "from numba import njit, prange\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "@njit(parallel=True)\n",
    "def get_greedy(v, model):\n",
    "    \"\"\"Compute a v-greedy policy.\"\"\"\n",
    "    β, R, γ, w_grid, y_grid, Q = model\n",
    "    σ = np.empty((w_grid.shape[0], y_grid.shape[0]), dtype=np.int32)\n",
    "    for i in prange(w_grid.shape[0]):\n",
    "        for j in prange(y_grid.shape[0]):\n",
    "            x_tmp = np.array([B(i, j, k, v, model) for k in\n",
    "                             np.arange(w_grid.shape[0])])\n",
    "            σ[i, j] = np.argmax(x_tmp)\n",
    "    return σ\n",
    "\n",
    "\n",
    "@njit\n",
    "def single_to_multi(m, yn):\n",
    "    # Function to extract (i, j) from m = i + (j-1)*yn\n",
    "    return (m//yn, m%yn)\n",
    "\n",
    "\n",
    "@njit(parallel=True)\n",
    "def get_value(σ, model):\n",
    "    \"\"\"Get the value v_σ of policy σ.\"\"\"\n",
    "    # Unpack and set up\n",
    "    β, R, γ, w_grid, y_grid, Q = model\n",
    "    w_idx, y_idx = np.arange(len(w_grid)), np.arange(len(y_grid))\n",
    "    wn, yn = len(w_grid), len(y_grid)\n",
    "    n = wn * yn\n",
    "    # Build P_σ and r_σ as multi-index arrays\n",
    "    P_σ = np.zeros((wn, yn, wn, yn))\n",
    "    r_σ = np.zeros((wn, yn))\n",
    "    for (i, j) in product(w_idx, y_idx):\n",
    "        w, y, w_1 = w_grid[i], y_grid[j], w_grid[σ[i, j]]\n",
    "        r_σ[i, j] = U(w + y - w_1/R, γ)\n",
    "        for (i_1, j_1) in product(w_idx, y_idx):\n",
    "            if i_1 == σ[i, j]:\n",
    "                P_σ[i, j, i_1, j_1] = Q[j, j_1]\n",
    "\n",
    "    # Solve for the value of σ\n",
    "    I = np.identity(n)\n",
    "    v_σ = np.linalg.solve((I - β * P_σ), r_σ)\n",
    "    # Return as multi-index array\n",
    "    v_σ = v_σ.reshape(wn, yn)\n",
    "    return v_σ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f02a74",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'simulate' from 'quantecon' (C:\\Users\\orect\\mambaforge\\envs\\pyFin\\Lib\\site-packages\\quantecon\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfinite_opt_saving_1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_greedy, get_value\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfinite_opt_saving_0\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_savings_model, T, T_σ\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mquantecon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MarkovChain, simulate\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalue_iteration\u001b[39m(model, tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m):\n\u001b[0;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Value function iteration routine.\"\"\"\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'simulate' from 'quantecon' (C:\\Users\\orect\\mambaforge\\envs\\pyFin\\Lib\\site-packages\\quantecon\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from quantecon import compute_fixed_point\n",
    "\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "import time\n",
    "from finite_opt_saving_1 import get_greedy, get_value\n",
    "from finite_opt_saving_0 import create_savings_model, T, T_σ\n",
    "from quantecon import MarkovChain, simulate\n",
    "\n",
    "\n",
    "def value_iteration(model, tol=1e-5):\n",
    "    \"\"\"Value function iteration routine.\"\"\"\n",
    "    vz = np.zeros((len(model.w_grid), len(model.y_grid)))\n",
    "    v_star = compute_fixed_point(lambda v: T(v, model), vz,\n",
    "                                 error_tol=tol, max_iter=1000, print_skip=25)\n",
    "    return get_greedy(v_star, model)\n",
    "\n",
    "\n",
    "@njit\n",
    "def policy_iteration(model):\n",
    "    \"\"\"Howard policy iteration routine.\"\"\"\n",
    "    wn, yn = len(model.w_grid), len(model.y_grid)\n",
    "    σ = np.ones((wn, yn), dtype=np.int32)\n",
    "    i, error = 0, 1.0\n",
    "    while error > 0:\n",
    "        v_σ = get_value(σ, model)\n",
    "        σ_new = get_greedy(v_σ, model)\n",
    "        error = np.max(np.abs(σ_new - σ))\n",
    "        σ = σ_new\n",
    "        i = i + 1\n",
    "        print(f\"Concluded loop {i} with error: {error}.\")\n",
    "    return σ\n",
    "\n",
    "\n",
    "@njit\n",
    "def optimistic_policy_iteration(model, tolerance=1e-5, m=100):\n",
    "    \"\"\"Optimistic policy iteration routine.\"\"\"\n",
    "    v = np.zeros((len(model.w_grid), len(model.y_grid)))\n",
    "    error = tolerance + 1\n",
    "    while error > tolerance:\n",
    "        last_v = v\n",
    "        σ = get_greedy(v, model)\n",
    "        for i in range(0, m):\n",
    "            v = T_σ(v, σ, model)\n",
    "        error = np.max(np.abs(v - last_v))\n",
    "    return get_greedy(v, model)\n",
    "\n",
    "# Simulations and inequality measures\n",
    "\n",
    "def simulate_wealth(m):\n",
    "\n",
    "    model = create_savings_model()\n",
    "    σ_star = optimistic_policy_iteration(model)\n",
    "    β, R, γ, w_grid, y_grid, Q = model\n",
    "\n",
    "    # Simulate labor income (indices rather than grid values)\n",
    "    mc = MarkovChain(Q)\n",
    "    y_idx_series = mc.simulate(ts_length=m)\n",
    "\n",
    "    # Compute corresponding wealth time series\n",
    "    w_idx_series = np.empty_like(y_idx_series)\n",
    "    w_idx_series[0] = 1  # initial condition\n",
    "    for t in range(m-1):\n",
    "        i, j = w_idx_series[t], y_idx_series[t]\n",
    "        w_idx_series[t+1] = σ_star[i, j]\n",
    "    w_series = w_grid[w_idx_series]\n",
    "\n",
    "    return w_series\n",
    "\n",
    "def lorenz(v):  # assumed sorted vector\n",
    "    S = np.cumsum(v)  # cumulative sums: [v[1], v[1] + v[2], ... ]\n",
    "    F = np.arange(1, len(v) + 1) / len(v)\n",
    "    L = S / S[-1]\n",
    "    return (F, L) # returns named tuple\n",
    "\n",
    "gini = lambda v: (2 * sum(i * y for (i, y) in enumerate(v))/sum(v) - (len(v) + 1))/len(v)\n",
    "\n",
    "# Plots\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_timing(m_vals=np.arange(1, 601, 10),\n",
    "                savefig=False):\n",
    "    model = create_savings_model(y_size=5)\n",
    "    print(\"Running Howard policy iteration.\")\n",
    "    t1 = time.time()\n",
    "    σ_pi = policy_iteration(model)\n",
    "    pi_time = time.time() - t1\n",
    "    print(f\"PI completed in {pi_time} seconds.\")\n",
    "    print(\"Running value function iteration.\")\n",
    "    t1 = time.time()\n",
    "    σ_vfi = value_iteration(model)\n",
    "    vfi_time = time.time() - t1\n",
    "    print(f\"VFI completed in {vfi_time} seconds.\")\n",
    "\n",
    "    assert np.allclose(σ_vfi, σ_pi), \"Warning: policies deviated.\"\n",
    "\n",
    "    opi_times = []\n",
    "    for m in m_vals:\n",
    "        print(f\"Running optimistic policy iteration with m={m}.\")\n",
    "        t1 = time.time()\n",
    "        σ_opi = optimistic_policy_iteration(model, m=m)\n",
    "        t2 = time.time()\n",
    "        assert np.allclose(σ_opi, σ_pi), \"Warning: policies deviated.\"\n",
    "        print(f\"OPI with m={m} completed in {t2-t1} seconds.\")\n",
    "        opi_times.append(t2-t1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.plot(m_vals, [vfi_time]*len(m_vals),\n",
    "            linewidth=2, label=\"value function iteration\")\n",
    "    ax.plot(m_vals, [pi_time]*len(m_vals),\n",
    "            linewidth=2, label=\"Howard policy iteration\")\n",
    "    ax.plot(m_vals, opi_times, linewidth=2,\n",
    "            label=\"optimistic policy iteration\")\n",
    "    ax.legend(frameon=False)\n",
    "    ax.set_xlabel(r\"$m$\")\n",
    "    ax.set_ylabel(\"time\")\n",
    "    if savefig:\n",
    "        fig.savefig(\"../figures/finite_opt_saving_2_1.png\")\n",
    "    return (pi_time, vfi_time, opi_times)\n",
    "\n",
    "\n",
    "def plot_policy(method=\"pi\", savefig=False):\n",
    "    model = create_savings_model()\n",
    "    β, R, γ, w_grid, y_grid, Q = model\n",
    "    if method == \"vfi\":\n",
    "        σ_star =  value_iteration(model)\n",
    "    elif method == \"pi\":\n",
    "        σ_star = policy_iteration(model)\n",
    "    else:\n",
    "        method = \"OPT\"\n",
    "        σ_star = optimistic_policy_iteration(model)\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.plot(w_grid, w_grid, \"k--\", label=r\"$45$\")\n",
    "    ax.plot(w_grid, w_grid[σ_star[:, 0]], label=r\"$\\sigma^*(\\cdot, y_1)$\")\n",
    "    ax.plot(w_grid, w_grid[σ_star[:, -1]], label=r\"$\\sigma^*(\\cdot, y_N)$\")\n",
    "    ax.legend()\n",
    "    plt.title(f\"Method: {method}\")\n",
    "    if savefig:\n",
    "        fig.savefig(f\"../figures/finite_opt_saving_2_2_{method}.png\")\n",
    "\n",
    "def plot_time_series(m=2_000, savefig=False):\n",
    "\n",
    "    w_series = simulate_wealth(m)\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.plot(w_series, label=\"w_t\")\n",
    "    ax.set_xlabel(\"time\")\n",
    "    ax.legend()\n",
    "    if savefig:\n",
    "        fig.savefig(\"../figures/finite_opt_saving_ts.pdf\")\n",
    "\n",
    "def plot_histogram(m=1_000_000, savefig=False):\n",
    "\n",
    "    w_series = simulate_wealth(m)\n",
    "    g = round(gini(w_series.sort()), ndigits=2)\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.hist(w_series, bins=40, density=True)\n",
    "    ax.set_xlabel(\"wealth\")\n",
    "    ax.text(15, 0.4, \"Gini = $g\")\n",
    "\n",
    "    if savefig:\n",
    "        fig.savefig(\"../figures/finite_opt_saving_hist.pdf\")\n",
    "\n",
    "def plot_lorenz(m=1_000_000, savefig=False):\n",
    "\n",
    "    w_series = simulate_wealth(m)\n",
    "    (F, L) = lorenz(w_series.sort())\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.plot(F, F, label=\"Lorenz curve, equality\")\n",
    "    ax.plot(F, L, label=\"Lorenz curve, wealth distribution\")\n",
    "    ax.legend()\n",
    "\n",
    "    if savefig:\n",
    "        fig.savefig(\"../figures/finite_opt_saving_lorenz.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb3fad94",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_timing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_timing\u001b[49m(savefig\u001b[38;5;241m=\u001b[39mtrue)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_timing' is not defined"
     ]
    }
   ],
   "source": [
    "plot_timing(savefig=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "907937e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_policy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_policy\u001b[49m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_policy' is not defined"
     ]
    }
   ],
   "source": [
    "plot_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dfadd19",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_time_series' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_time_series\u001b[49m(savefig\u001b[38;5;241m=\u001b[39mtrue)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_time_series' is not defined"
     ]
    }
   ],
   "source": [
    "plot_time_series(savefig=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0b7fa51",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_histogram' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_histogram\u001b[49m(savefig\u001b[38;5;241m=\u001b[39mtrue)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_histogram' is not defined"
     ]
    }
   ],
   "source": [
    "plot_histogram(savefig=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e507ef6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_lorenz' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_lorenz\u001b[49m(savefig\u001b[38;5;241m=\u001b[39mtrue)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_lorenz' is not defined"
     ]
    }
   ],
   "source": [
    "plot_lorenz(savefig=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d255f8f",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from quantecon import compute_fixed_point\n",
    "from quantecon.markov import tauchen, MarkovChain\n",
    "\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from numba import njit, prange\n",
    "import time\n",
    "\n",
    "\n",
    "# NamedTuple Model\n",
    "Model = namedtuple(\"Model\", (\"β\", \"a_0\", \"a_1\", \"γ\", \"c\",\n",
    "                             \"y_grid\", \"z_grid\", \"Q\"))\n",
    "\n",
    "\n",
    "def create_investment_model(\n",
    "        r=0.04,                               # Interest rate\n",
    "        a_0=10.0, a_1=1.0,                    # Demand parameters\n",
    "        γ=25.0, c=1.0,                        # Adjustment and unit cost\n",
    "        y_min=0.0, y_max=20.0, y_size=100,    # Grid for output\n",
    "        ρ=0.9, ν=1.0,                         # AR(1) parameters\n",
    "        z_size=25):                           # Grid size for shock\n",
    "    β = 1/(1+r)\n",
    "    y_grid = np.linspace(y_min, y_max, y_size)\n",
    "    mc = tauchen(ρ, ν, n=y_size)\n",
    "    z_grid, Q = mc.state_values, mc.P\n",
    "    return Model(β=β, a_0=a_0, a_1=a_1, γ=γ, c=c,\n",
    "          y_grid=y_grid, z_grid=z_grid, Q=Q)\n",
    "\n",
    "\n",
    "@njit\n",
    "def B(i, j, k, v, model):\n",
    "    \"\"\"\n",
    "    The aggregator B is given by\n",
    "\n",
    "        B(y, z, y′) = r(y, z, y′) + β Σ_z′ v(y′, z′) Q(z, z′).\"\n",
    "\n",
    "    where\n",
    "\n",
    "        r(y, z, y′) := (a_0 - a_1 * y + z - c) y - γ * (y′ - y)^2\n",
    "\n",
    "    \"\"\"\n",
    "    β, a_0, a_1, γ, c, y_grid, z_grid, Q = model\n",
    "    y, z, y_1 = y_grid[i], z_grid[j], y_grid[k]\n",
    "    r = (a_0 - a_1 * y + z - c) * y - γ * (y_1 - y)**2\n",
    "    return r + β * np.dot(v[k, :], Q[j, :])\n",
    "\n",
    "\n",
    "@njit(parallel=True)\n",
    "def T_σ(v, σ, model):\n",
    "    \"\"\"The policy operator.\"\"\"\n",
    "    v_new = np.empty_like(v)\n",
    "    for i in prange(len(model.y_grid)):\n",
    "        for j in prange(len(model.z_grid)):\n",
    "            v_new[i, j] = B(i, j, σ[i, j], v, model)\n",
    "    return v_new\n",
    "\n",
    "\n",
    "@njit(parallel=True)\n",
    "def T(v, model):\n",
    "    \"\"\"The Bellman operator.\"\"\"\n",
    "    v_new = np.empty_like(v)\n",
    "    for i in prange(len(model.y_grid)):\n",
    "        for j in prange(len(model.z_grid)):\n",
    "            tmp = np.array([B(i, j, k, v, model) for k\n",
    "                            in np.arange(len(model.y_grid))])\n",
    "            v_new[i, j] = np.max(tmp)\n",
    "    return v_new\n",
    "\n",
    "\n",
    "@njit(parallel=True)\n",
    "def get_greedy(v, model):\n",
    "    \"\"\"Compute a v-greedy policy.\"\"\"\n",
    "    n, m = len(model.y_grid), len(model.z_grid)\n",
    "    σ = np.empty((n, m), dtype=np.int32)\n",
    "    for i in prange(n):\n",
    "        for j in prange(m):\n",
    "            tmp = np.array([B(i, j, k, v, model) for k\n",
    "                            in np.arange(n)])\n",
    "            σ[i, j] = np.argmax(tmp)\n",
    "    return σ\n",
    "\n",
    "\n",
    "\n",
    "def value_iteration(model, tol=1e-5):\n",
    "    \"\"\"Value function iteration routine.\"\"\"\n",
    "    vz = np.zeros((len(model.y_grid), len(model.z_grid)))\n",
    "    v_star = compute_fixed_point(lambda v: T(v, model), vz,\n",
    "                                 error_tol=tol, max_iter=1000, print_skip=25)\n",
    "    return get_greedy(v_star, model)\n",
    "\n",
    "\n",
    "@njit\n",
    "def single_to_multi(m, zn):\n",
    "    # Function to extract (i, j) from m = i + (j-1)*zn\n",
    "    return (m//zn, m%zn)\n",
    "\n",
    "\n",
    "@njit(parallel=True)\n",
    "def get_value(σ, model):\n",
    "    \"\"\"Get the value v_σ of policy σ.\"\"\"\n",
    "    # Unpack and set up\n",
    "    β, a_0, a_1, γ, c, y_grid, z_grid, Q = model\n",
    "    yn, zn = len(y_grid), len(z_grid)\n",
    "    n = yn * zn\n",
    "    # Allocate and create single index versions of P_σ and r_σ\n",
    "    P_σ = np.zeros((n, n))\n",
    "    r_σ = np.zeros(n)\n",
    "    for m in prange(n):\n",
    "        i, j = single_to_multi(m, zn)\n",
    "        y, z, y_1 = y_grid[i], z_grid[j], y_grid[σ[i, j]]\n",
    "        r_σ[m] = (a_0 - a_1 * y + z - c) * y - γ * (y_1 - y)**2\n",
    "        for m_1 in prange(n):\n",
    "            i_1, j_1 = single_to_multi(m_1, zn)\n",
    "            if i_1 == σ[i, j]:\n",
    "                P_σ[m, m_1] = Q[j, j_1]\n",
    "\n",
    "    I = np.identity(n)\n",
    "    # Solve for the value of σ\n",
    "    v_σ = np.linalg.solve((I - β * P_σ), r_σ)\n",
    "    # Return as multi-index array\n",
    "    v_σ = v_σ.reshape(yn, zn)\n",
    "    return v_σ\n",
    "\n",
    "\n",
    "@njit\n",
    "def policy_iteration(model):\n",
    "    \"\"\"Howard policy iteration routine.\"\"\"\n",
    "    yn, zn = len(model.y_grid), len(model.z_grid)\n",
    "    σ = np.ones((yn, zn), dtype=np.int32)\n",
    "    i, error = 0, 1.0\n",
    "    while error > 0:\n",
    "        v_σ = get_value(σ, model)\n",
    "        σ_new = get_greedy(v_σ, model)\n",
    "        error = np.max(np.abs(σ_new - σ))\n",
    "        σ = σ_new\n",
    "        i = i + 1\n",
    "        print(f\"Concluded loop {i} with error: {error}.\")\n",
    "    return σ\n",
    "\n",
    "\n",
    "@njit\n",
    "def optimistic_policy_iteration(model, tol=1e-5, m=100):\n",
    "    \"\"\"Optimistic policy iteration routine.\"\"\"\n",
    "    v = np.zeros((len(model.y_grid), len(model.z_grid)))\n",
    "    error = tol + 1\n",
    "    while error > tol:\n",
    "        last_v = v\n",
    "        σ = get_greedy(v, model)\n",
    "        for i in range(m):\n",
    "            v = T_σ(v, σ, model)\n",
    "        error = np.max(np.abs(v - last_v))\n",
    "    return get_greedy(v, model)\n",
    "\n",
    "\n",
    "# Plots\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_policy(savefig=False, figname=\"../figures/finite_lq_0.pdf\"):\n",
    "    model = create_investment_model()\n",
    "    β, a_0, a_1, γ, c, y_grid, z_grid, Q = model\n",
    "    σ_star = optimistic_policy_iteration(model)\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.plot(y_grid, y_grid, \"k--\", label=r\"$45$\")\n",
    "    ax.plot(y_grid, y_grid[σ_star[:, 0]], label=r\"$\\sigma^*(\\cdot, z_1)$\")\n",
    "    ax.plot(y_grid, y_grid[σ_star[:, -1]], label=\"$\\sigma^*(\\cdot, z_N)$\")\n",
    "    ax.legend()\n",
    "    if savefig:\n",
    "        fig.savefig(figname)\n",
    "\n",
    "\n",
    "def plot_sim(savefig=False, figname=\"../figures/finite_lq_1.pdf\"):\n",
    "    ts_length = 200\n",
    "\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(9, 11.2))\n",
    "\n",
    "    for (ax, γ) in zip(axes, (1, 10, 20, 30)):\n",
    "        model = create_investment_model(γ=γ)\n",
    "        β, a_0, a_1, γ, c, y_grid, z_grid, Q = model\n",
    "        σ_star = optimistic_policy_iteration(model)\n",
    "        mc = MarkovChain(Q, z_grid)\n",
    "\n",
    "        z_sim_idx = mc.simulate_indices(ts_length)\n",
    "        z_sim = z_grid[z_sim_idx]\n",
    "\n",
    "        y_sim_idx = np.empty(ts_length, dtype=np.int32)\n",
    "        y_1 = (a_0 - c + z_sim[1]) / (2 * a_1)\n",
    "\n",
    "        y_sim_idx[0] = np.searchsorted(y_grid, y_1)\n",
    "        for t in range(ts_length-1):\n",
    "            y_sim_idx[t+1] = σ_star[y_sim_idx[t], z_sim_idx[t]]\n",
    "        y_sim = y_grid[y_sim_idx]\n",
    "        y_bar_sim = (a_0 - c + z_sim) / (2 * a_1)\n",
    "\n",
    "        ax.plot(np.arange(1, ts_length+1), y_sim, label=r\"$Y_t$\")\n",
    "        ax.plot(np.arange(1, ts_length+1), y_bar_sim, label=r\"$\\bar Y_t$\")\n",
    "        ax.legend(frameon=False, loc=\"upper right\")\n",
    "        ax.set_ylabel(\"output\")\n",
    "        ax.set_ylim(1, 9)\n",
    "        ax.set_title(r\"$\\gamma = $\" + f\"{γ}\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    if savefig:\n",
    "        fig.savefig(figname)\n",
    "\n",
    "\n",
    "def plot_timing(m_vals=np.arange(1, 601, 10),\n",
    "                savefig=False,\n",
    "                figname=\"../figures/finite_lq_time.pdf\"\n",
    "    ):\n",
    "    # NOTE: Uncomment the following lines in this function to\n",
    "    # include Policy iteration plot\n",
    "    model = create_investment_model()\n",
    "    # print(\"Running Howard policy iteration.\")\n",
    "    # t1 = time.time()\n",
    "    # σ_pi = policy_iteration(model)\n",
    "    # pi_time = time.time() - t1\n",
    "    # print(f\"PI completed in {pi_time} seconds.\")\n",
    "    print(\"Running value function iteration.\")\n",
    "    t1 = time.time()\n",
    "    σ_vfi = value_iteration(model)\n",
    "    vfi_time = time.time() - t1\n",
    "    print(f\"VFI completed in {vfi_time} seconds.\")\n",
    "    opi_times = []\n",
    "    for m in m_vals:\n",
    "        print(f\"Running optimistic policy iteration with m={m}.\")\n",
    "        t1 = time.time()\n",
    "        σ_opi = optimistic_policy_iteration(model, m=m, tol=1e-5)\n",
    "        t2 = time.time()\n",
    "        print(f\"OPI with m={m} completed in {t2-t1} seconds.\")\n",
    "        opi_times.append(t2-t1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.plot(m_vals, [vfi_time]*len(m_vals),\n",
    "            linewidth=2, label=\"value function iteration\")\n",
    "    # ax.plot(m_vals, [pi_time]*len(m_vals),\n",
    "    #         linewidth=2, label=\"Howard policy iteration\")\n",
    "    ax.plot(m_vals, opi_times, linewidth=2, label=\"optimistic policy iteration\")\n",
    "    ax.legend(frameon=False)\n",
    "    ax.set_xlabel(r\"$m$\")\n",
    "    ax.set_ylabel(\"time\")\n",
    "    if savefig:\n",
    "        fig.savefig(figname)\n",
    "    return (vfi_time, opi_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bb964a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tauchen() got multiple values for argument 'n'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 161\u001b[0m, in \u001b[0;36mplot_policy\u001b[1;34m(savefig, figname)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_policy\u001b[39m(savefig\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, figname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../figures/finite_lq_0.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 161\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_investment_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m     β, a_0, a_1, γ, c, y_grid, z_grid, Q \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m    163\u001b[0m     σ_star \u001b[38;5;241m=\u001b[39m optimistic_policy_iteration(model)\n",
      "Cell \u001b[1;32mIn[12], line 24\u001b[0m, in \u001b[0;36mcreate_investment_model\u001b[1;34m(r, a_0, a_1, γ, c, y_min, y_max, y_size, ρ, ν, z_size)\u001b[0m\n\u001b[0;32m     22\u001b[0m β \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39mr)\n\u001b[0;32m     23\u001b[0m y_grid \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(y_min, y_max, y_size)\n\u001b[1;32m---> 24\u001b[0m mc \u001b[38;5;241m=\u001b[39m \u001b[43mtauchen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mρ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mν\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m z_grid, Q \u001b[38;5;241m=\u001b[39m mc\u001b[38;5;241m.\u001b[39mstate_values, mc\u001b[38;5;241m.\u001b[39mP\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Model(β\u001b[38;5;241m=\u001b[39mβ, a_0\u001b[38;5;241m=\u001b[39ma_0, a_1\u001b[38;5;241m=\u001b[39ma_1, γ\u001b[38;5;241m=\u001b[39mγ, c\u001b[38;5;241m=\u001b[39mc,\n\u001b[0;32m     27\u001b[0m       y_grid\u001b[38;5;241m=\u001b[39my_grid, z_grid\u001b[38;5;241m=\u001b[39mz_grid, Q\u001b[38;5;241m=\u001b[39mQ)\n",
      "\u001b[1;31mTypeError\u001b[0m: tauchen() got multiple values for argument 'n'"
     ]
    }
   ],
   "source": [
    "plot_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2019669b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_sim(savefig\u001b[38;5;241m=\u001b[39m\u001b[43mtrue\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'true' is not defined"
     ]
    }
   ],
   "source": [
    "plot_sim(savefig=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2afd2459",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_timing(savefig\u001b[38;5;241m=\u001b[39m\u001b[43mtrue\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'true' is not defined"
     ]
    }
   ],
   "source": [
    "plot_timing(savefig=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "086f7a7f",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from quantecon.markov import tauchen, MarkovChain\n",
    "\n",
    "from collections import namedtuple\n",
    "from numba import njit, prange\n",
    "\n",
    "\n",
    "# NamedTuple Model\n",
    "Model = namedtuple(\"Model\", (\"β\", \"κ\", \"α\", \"p\", \"w\", \"l_grid\",\n",
    "                             \"z_grid\", \"Q\"))\n",
    "\n",
    "\n",
    "def create_hiring_model(\n",
    "        r=0.04,                              # Interest rate\n",
    "        κ=1.0,                               # Adjustment cost\n",
    "        α=0.4,                               # Production parameter\n",
    "        p=1.0, w=1.0,                        # Price and wage\n",
    "        l_min=0.0, l_max=30.0, l_size=100,   # Grid for labor\n",
    "        ρ=0.9, ν=0.4, b=1.0,                 # AR(1) parameters\n",
    "        z_size=100):                         # Grid size for shock\n",
    "    β = 1/(1+r)\n",
    "    l_grid = np.linspace(l_min, l_max, l_size)\n",
    "    mc = tauchen(ρ, ν, b, 6, z_size)\n",
    "    z_grid, Q = mc.state_values, mc.P\n",
    "    return Model(β=β, κ=κ, α=α, p=p, w=w,\n",
    "                 l_grid=l_grid, z_grid=z_grid, Q=Q)\n",
    "\n",
    "\n",
    "@njit\n",
    "def B(i, j, k, v, model):\n",
    "    \"\"\"\n",
    "    The aggregator B is given by\n",
    "\n",
    "        B(l, z, l′) = r(l, z, l′) + β Σ_z′ v(l′, z′) Q(z, z′).\"\n",
    "\n",
    "    where\n",
    "\n",
    "        r(l, z, l′) := p * z * f(l) - w * l - κ 1{l != l′}\n",
    "\n",
    "    \"\"\"\n",
    "    β, κ, α, p, w, l_grid, z_grid, Q = model\n",
    "    l, z, l_1 = l_grid[i], z_grid[j], l_grid[k]\n",
    "    r = p * z * l**α - w * l - κ * (l != l_1)\n",
    "    return r + β * np.dot(v[k, :], Q[j, :])\n",
    "\n",
    "\n",
    "@njit(parallel=True)\n",
    "def T_σ(v, σ, model):\n",
    "    \"\"\"The policy operator.\"\"\"\n",
    "    v_new = np.empty_like(v)\n",
    "    for i in prange(len(model.l_grid)):\n",
    "        for j in prange(len(model.z_grid)):\n",
    "            v_new[i, j] = B(i, j, σ[i, j], v, model)\n",
    "    return v_new\n",
    "\n",
    "\n",
    "@njit(parallel=True)\n",
    "def get_greedy(v, model):\n",
    "    \"\"\"Compute a v-greedy policy.\"\"\"\n",
    "    β, κ, α, p, w, l_grid, z_grid, Q = model\n",
    "    n, m = len(l_grid), len(z_grid)\n",
    "    σ = np.empty((n, m), dtype=np.int32)\n",
    "    for i in prange(n):\n",
    "        for j in prange(m):\n",
    "            tmp = np.array([B(i, j, k, v, model) for k\n",
    "                            in np.arange(n)])\n",
    "            σ[i, j] = np.argmax(tmp)\n",
    "    return σ\n",
    "\n",
    "\n",
    "@njit\n",
    "def optimistic_policy_iteration(model, tolerance=1e-5, m=100):\n",
    "    \"\"\"Optimistic policy iteration routine.\"\"\"\n",
    "    v = np.zeros((len(model.l_grid), len(model.z_grid)))\n",
    "    error = tolerance + 1\n",
    "    while error > tolerance:\n",
    "        last_v = v\n",
    "        σ = get_greedy(v, model)\n",
    "        for i in range(m):\n",
    "            v = T_σ(v, σ, model)\n",
    "        error = np.max(np.abs(v - last_v))\n",
    "    return get_greedy(v, model)\n",
    "\n",
    "\n",
    "# Plots\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_policy(savefig=False,\n",
    "                figname=\"../figures/firm_hiring_pol.pdf\"):\n",
    "    model = create_hiring_model()\n",
    "    β, κ, α, p, w, l_grid, z_grid, Q = model\n",
    "    σ_star = optimistic_policy_iteration(model)\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.plot(l_grid, l_grid, \"k--\", label=r\"$45$\")\n",
    "    ax.plot(l_grid, l_grid[σ_star[:, 0]], label=r\"$\\sigma^*(\\cdot, z_1)$\")\n",
    "    ax.plot(l_grid, l_grid[σ_star[:, -1]], label=r\"$\\sigma^*(\\cdot, z_N)$\")\n",
    "    ax.legend()\n",
    "    if savefig:\n",
    "        fig.savefig(figname)\n",
    "\n",
    "\n",
    "def sim_dynamics(model, ts_length):\n",
    "    β, κ, α, p, w, l_grid, z_grid, Q = model\n",
    "    σ_star = optimistic_policy_iteration(model)\n",
    "    mc = MarkovChain(Q, z_grid)\n",
    "    z_sim_idx = mc.simulate_indices(ts_length)\n",
    "    z_sim = z_grid[z_sim_idx]\n",
    "    l_sim_idx = np.empty(ts_length, dtype=np.int32)\n",
    "    l_sim_idx[0] = 32\n",
    "    for t in range(ts_length-1):\n",
    "        l_sim_idx[t+1] = σ_star[l_sim_idx[t], z_sim_idx[t]]\n",
    "    l_sim = l_grid[l_sim_idx]\n",
    "\n",
    "    y_sim = np.empty_like(l_sim)\n",
    "    for (i, l) in enumerate(l_sim):\n",
    "        y_sim[i] = p * z_sim[i] * l_sim[i]**α\n",
    "\n",
    "    t = ts_length - 1\n",
    "    l_g, y_g, z_g = np.zeros(t), np.zeros(t), np.zeros(t)\n",
    "\n",
    "    for i in range(t):\n",
    "        l_g[i] = (l_sim[i+1] - l_sim[i]) / l_sim[i]\n",
    "        y_g[i] = (y_sim[i+1] - y_sim[i]) / y_sim[i]\n",
    "        z_g[i] = (z_sim[i+1] - z_sim[i]) / z_sim[i]\n",
    "\n",
    "    return l_sim, y_sim, z_sim, l_g, y_g, z_g\n",
    "\n",
    "\n",
    "def plot_sim(savefig=False,\n",
    "             figname=\"../figures/firm_hiring_ts.pdf\",\n",
    "             ts_length = 250):\n",
    "    model = create_hiring_model()\n",
    "    β, κ, α, p, w, l_grid, z_grid, Q = model\n",
    "    l_sim, y_sim, z_sim, l_g, y_g, z_g = sim_dynamics(model, ts_length)\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    x_grid = np.arange(ts_length)\n",
    "    ax.plot(x_grid, l_sim, label=r\"$\\ell_t$\")\n",
    "    ax.plot(x_grid, z_sim, alpha=0.6, label=r\"$Z_t$\")\n",
    "    ax.legend(frameon=False)\n",
    "    ax.set_ylabel(\"employment\")\n",
    "    ax.set_xlabel(\"time\")\n",
    "\n",
    "    if savefig:\n",
    "        fig.savefig(figname)\n",
    "\n",
    "\n",
    "def plot_growth(savefig=False,\n",
    "                figname=\"../figures/firm_hiring_g.pdf\",\n",
    "                ts_length = 10_000_000):\n",
    "\n",
    "    model = create_hiring_model()\n",
    "    β, κ, α, p, w, l_grid, z_grid, Q = model\n",
    "    l_sim, y_sim, z_sim, l_g, y_g, z_g = sim_dynamics(model, ts_length)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(l_g, alpha=0.6, bins=100)\n",
    "    ax.set_xlabel(\"growth\")\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1)\n",
    "    series = y_g, z_g\n",
    "    for (ax, g) in zip(axes, series):\n",
    "        ax.hist(g, alpha=0.6, bins=100)\n",
    "        ax.set_xlabel(\"growth\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if savefig:\n",
    "        fig.savefig(figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f96a7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\orect\\AppData\\Local\\Temp\\ipykernel_9268\\1488942556.py:23: UserWarning: The API of tauchen has changed from `tauchen(rho, sigma_u, b=0., m=3, n=7)` to `tauchen(n, rho, sigma, mu=0., n_std=3)`. To find more details please visit: https://github.com/QuantEcon/QuantEcon.py/issues/663.\n",
      "  mc = tauchen(ρ, ν, b, 6, z_size)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 92\u001b[0m, in \u001b[0;36mplot_policy\u001b[1;34m(savefig, figname)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_policy\u001b[39m(savefig\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     91\u001b[0m                 figname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../figures/firm_hiring_pol.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 92\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_hiring_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m     β, κ, α, p, w, l_grid, z_grid, Q \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m     94\u001b[0m     σ_star \u001b[38;5;241m=\u001b[39m optimistic_policy_iteration(model)\n",
      "Cell \u001b[1;32mIn[16], line 23\u001b[0m, in \u001b[0;36mcreate_hiring_model\u001b[1;34m(r, κ, α, p, w, l_min, l_max, l_size, ρ, ν, b, z_size)\u001b[0m\n\u001b[0;32m     21\u001b[0m β \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39mr)\n\u001b[0;32m     22\u001b[0m l_grid \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(l_min, l_max, l_size)\n\u001b[1;32m---> 23\u001b[0m mc \u001b[38;5;241m=\u001b[39m \u001b[43mtauchen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mρ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mν\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m z_grid, Q \u001b[38;5;241m=\u001b[39m mc\u001b[38;5;241m.\u001b[39mstate_values, mc\u001b[38;5;241m.\u001b[39mP\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Model(β\u001b[38;5;241m=\u001b[39mβ, κ\u001b[38;5;241m=\u001b[39mκ, α\u001b[38;5;241m=\u001b[39mα, p\u001b[38;5;241m=\u001b[39mp, w\u001b[38;5;241m=\u001b[39mw,\n\u001b[0;32m     26\u001b[0m              l_grid\u001b[38;5;241m=\u001b[39ml_grid, z_grid\u001b[38;5;241m=\u001b[39mz_grid, Q\u001b[38;5;241m=\u001b[39mQ)\n",
      "File \u001b[1;32m~\\mambaforge\\envs\\pyFin\\Lib\\site-packages\\quantecon\\markov\\approximation.py:215\u001b[0m, in \u001b[0;36mtauchen\u001b[1;34m(n, rho, sigma, mu, n_std)\u001b[0m\n\u001b[0;32m    212\u001b[0m x_min \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mx_max\n\u001b[0;32m    214\u001b[0m \u001b[38;5;66;03m# discretized state space for demeaned y_t\u001b[39;00m\n\u001b[1;32m--> 215\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinspace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m step \u001b[38;5;241m=\u001b[39m (x_max \u001b[38;5;241m-\u001b[39m x_min) \u001b[38;5;241m/\u001b[39m (n \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    218\u001b[0m half_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m step\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mlinspace\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\mambaforge\\envs\\pyFin\\Lib\\site-packages\\numpy\\core\\function_base.py:121\u001b[0m, in \u001b[0;36mlinspace\u001b[1;34m(start, stop, num, endpoint, retstep, dtype, axis)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_linspace_dispatcher)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlinspace\u001b[39m(start, stop, num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, endpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, retstep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     25\u001b[0m              axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m    Return evenly spaced numbers over a specified interval.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    119\u001b[0m \n\u001b[0;32m    120\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m     num \u001b[38;5;241m=\u001b[39m operator\u001b[38;5;241m.\u001b[39mindex(num)\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    123\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of samples, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, must be non-negative.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m num)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "plot_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50b9a7f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_sim(savefig\u001b[38;5;241m=\u001b[39m\u001b[43mtrue\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'true' is not defined"
     ]
    }
   ],
   "source": [
    "plot_sim(savefig=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bd529f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_growth(savefig\u001b[38;5;241m=\u001b[39m\u001b[43mtrue\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'true' is not defined"
     ]
    }
   ],
   "source": [
    "plot_growth(savefig=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b4c6d48",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from quantecon import tauchen, MarkovChain\n",
    "\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from numba import njit, prange\n",
    "from math import floor\n",
    "\n",
    "\n",
    "# NamedTuple Model\n",
    "Model = namedtuple(\"Model\", (\"β\", \"R\", \"γ\", \"η_grid\", \"φ\",\n",
    "                             \"w_grid\", \"y_grid\", \"Q\"))\n",
    "\n",
    "\n",
    "def create_savings_model(β=0.98, γ=2.5,\n",
    "                         w_min=0.01, w_max=20.0, w_size=100,\n",
    "                         ρ=0.9, ν=0.1, y_size=20,\n",
    "                         η_min=-0.25, η_max=0.25, η_size=30):\n",
    "    η_grid = np.linspace(η_min, η_max, η_size)\n",
    "    φ = np.ones(η_size) * (1 / η_size)  # Uniform distributoin\n",
    "    w_grid = np.linspace(w_min, w_max, w_size)\n",
    "    mc = tauchen(ρ, ν, n=y_size)\n",
    "    y_grid, Q = np.exp(mc.state_values), mc.P\n",
    "    return Model(β=β, γ=γ, η_grid=η_grid, φ=φ, w_grid=w_grid,\n",
    "                 y_grid=y_grid, Q=Q)\n",
    "\n",
    "\n",
    "## == Functions for regular OPI == ##\n",
    "\n",
    "@njit\n",
    "def U(c, γ):\n",
    "    return c**(1-γ)/(1-γ)\n",
    "\n",
    "\n",
    "@njit(parallel=True)\n",
    "def B(i, j, k, l, v, model):\n",
    "    \"\"\"\n",
    "    The function\n",
    "\n",
    "    B(w, y, η, w′) = u(w + y - w′/η)) + β Σ v(w′, y′, η′) Q(y, y′) ϕ(η′)\n",
    "\n",
    "    \"\"\"\n",
    "    β, γ, η_grid, φ, w_grid, y_grid, Q = model\n",
    "    w, y, η, w_1 = w_grid[i], y_grid[j], η_grid[k], w_grid[l]\n",
    "    c = w + y - (w_1 / η)\n",
    "    exp_value = 0.0\n",
    "    for m in prange(len(y_grid)):\n",
    "        for n in prange(len(η_grid)):\n",
    "            exp_value += v[l, m, n] * Q[j, m] * φ[n]\n",
    "    return U(c, γ) + β * exp_value if c > 0 else -np.inf\n",
    "\n",
    "\n",
    "@njit(parallel=True)\n",
    "def T_σ(v, σ, model):\n",
    "    \"\"\"The policy operator.\"\"\"\n",
    "    β, γ, η_grid, φ, w_grid, y_grid, Q = model\n",
    "    v_new = np.empty_like(v)\n",
    "    for i in prange(len(w_grid)):\n",
    "        for j in prange(len(y_grid)):\n",
    "            for k in prange(len(η_grid)):\n",
    "                v_new[i, j, k] = B(i, j, k, σ[i, j, k], v, model)\n",
    "    return v_new\n",
    "\n",
    "\n",
    "@njit(parallel=True)\n",
    "def get_greedy(v, model):\n",
    "    \"\"\"Compute a v-greedy policy.\"\"\"\n",
    "    β, γ, η_grid, φ, w_grid, y_grid, Q = model\n",
    "    w_n, y_n, η_n = len(w_grid), len(y_grid), len(η_grid)\n",
    "    σ = np.empty((w_n, y_n, η_n), dtype=np.int32)\n",
    "    for i in prange(w_n):\n",
    "        for j in prange(y_n):\n",
    "            for k in prange(η_n):\n",
    "                _tmp = np.array([B(i, j, k, l, v, model) for l\n",
    "                                in range(w_n)])\n",
    "                σ[i, j, k] = np.argmax(_tmp)\n",
    "    return σ\n",
    "\n",
    "\n",
    "def optimistic_policy_iteration(model, tolerance=1e-5, m=100):\n",
    "    \"\"\"Optimistic policy iteration routine.\"\"\"\n",
    "    β, γ, η_grid, φ, w_grid, y_grid, Q = model\n",
    "    w_n, y_n, η_n = len(w_grid), len(y_grid), len(η_grid)\n",
    "    v = np.zeros((w_n, y_n, η_n))\n",
    "    error = tolerance + 1\n",
    "    while error > tolerance:\n",
    "        last_v = v\n",
    "        σ = get_greedy(v, model)\n",
    "        for i in range(m):\n",
    "            v = T_σ(v, σ, model)\n",
    "        error = np.max(np.abs(v - last_v))\n",
    "        print(f\"OPI current error = {error}\")\n",
    "    return get_greedy(v, model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## == Functions for modified OPI == ##\n",
    "\n",
    "\n",
    "@njit\n",
    "def D(i, j, k, l, g, model):\n",
    "    \"\"\"D(w, y, η, w′, g) = u(w + y - w′/η) + β g(y, w′).\"\"\"\n",
    "    β, γ, η_grid, φ, w_grid, y_grid, Q = model\n",
    "    w, y, η, w_1 = w_grid[i], y_grid[j], η_grid[k], w_grid[l]\n",
    "    c = w + y + η - (w_1 / R)\n",
    "    return U(c, γ) + β * g[j, l] if c > 0 else -np.inf\n",
    "\n",
    "\n",
    "@njit(parallel=True)\n",
    "def get_g_greedy(g, model):\n",
    "    \"\"\"Compute a g-greedy policy.\"\"\"\n",
    "    β, γ, η_grid, φ, w_grid, y_grid, Q = model\n",
    "    w_n, y_n, η_n = len(w_grid), len(y_grid), len(η_grid)\n",
    "    σ = np.empty((w_n, y_n, η_n), dtype=np.int32)\n",
    "    for i in prange(w_n):\n",
    "        for j in prange(y_n):\n",
    "            for k in prange(η_n):\n",
    "                _tmp = np.array([D(i, j, k, l, g, model) for l\n",
    "                                in range(w_n)])\n",
    "                σ[i, j, k] = np.argmax(_tmp)\n",
    "    return σ\n",
    "\n",
    "\n",
    "@njit(parallel=True)\n",
    "def R_σ(g, σ, model):\n",
    "    \"\"\"The modified policy operator.\"\"\"\n",
    "    β, γ, η_grid, φ, w_grid, y_grid, Q = model\n",
    "    w_n, y_n, η_n = len(w_grid), len(y_grid), len(η_grid)\n",
    "    g_new = np.empty_like(g)\n",
    "    for j in prange(y_n):\n",
    "        for i_1 in prange(w_n):\n",
    "            out = 0.0\n",
    "            for j_1 in prange(y_n):\n",
    "                for k_1 in prange(η_n):\n",
    "                    out += D(i_1, j_1, k_1, σ[i_1, j_1, k_1], g,\n",
    "                             model) * Q[j, j_1] * φ[k_1]\n",
    "            g_new[j, i_1] = out\n",
    "    return g_new\n",
    "\n",
    "\n",
    "def mod_opi(model, tolerance=1e-5, m=100):\n",
    "    \"\"\"Modified optimistic policy iteration routine.\"\"\"\n",
    "    β, γ, η_grid, φ, w_grid, y_grid, Q = model\n",
    "    g = np.zeros((len(y_grid), len(w_grid)))\n",
    "    error = tolerance + 1\n",
    "    while error > tolerance:\n",
    "        last_g = g\n",
    "        σ = get_g_greedy(g, model)\n",
    "        for i in range(m):\n",
    "            g = R_σ(g, σ, model)\n",
    "        error = np.max(np.abs(g - last_g))\n",
    "        print(f\"OPI current error = {error}\")\n",
    "    return get_g_greedy(g, model)\n",
    "\n",
    "\n",
    "def simulate_wealth(m):\n",
    "\n",
    "    model = create_savings_model()\n",
    "    σ_star = mod_opi(model)\n",
    "    β, γ, η_grid, φ, w_grid, y_grid, Q = model\n",
    "\n",
    "    # Simulate labor income\n",
    "    mc = MarkovChain(Q)\n",
    "    y_idx_series = mc.simulate(ts_length=m)\n",
    "\n",
    "    # IID Markov chain with uniform draws\n",
    "    l = len(η_grid)\n",
    "    mc = MarkovChain(np.ones((l, l)) / l)\n",
    "    η_idx_series = mc.simulate(ts_length=m)\n",
    "\n",
    "    w_idx_series = np.empty_like(y_idx_series)\n",
    "    w_idx_series[0] = 1  # initial condition\n",
    "    for t in range(m-1):\n",
    "        i, j, k = w_idx_series[t], y_idx_series[t], η_idx_series[t]\n",
    "        w_idx_series[t+1] = σ_star[i, j, k]\n",
    "    w_series = w_grid[w_idx_series]\n",
    "\n",
    "    return w_series\n",
    "\n",
    "def lorenz(v):  # assumed sorted vector\n",
    "    S = np.cumsum(v)  # cumulative sums: [v[1], v[1] + v[2], ... ]\n",
    "    F = np.arange(1, len(v) + 1) / len(v)\n",
    "    L = S / S[-1]\n",
    "    return (F, L) # returns named tuple\n",
    "\n",
    "gini = lambda v: (2 * sum(i * y for (i, y) in enumerate(v))/sum(v) - (len(v) + 1))/len(v)\n",
    "\n",
    "# Plots\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_contours(savefig=False,\n",
    "                  figname=\"../figures/modified_opt_savings_1.pdf\"):\n",
    "\n",
    "    model = create_savings_model()\n",
    "    β, γ, η_grid, φ, w_grid, y_grid, Q = model\n",
    "    σ_star = optimistic_policy_iteration(model)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(10, 8))\n",
    "    y_n, η_n = len(y_grid), len(η_grid)\n",
    "    y_idx, η_idx = np.arange(y_n), np.arange(η_n)\n",
    "    H = np.zeros((y_n, η_n))\n",
    "\n",
    "    w_indices = (0, len(w_grid)-1)\n",
    "    titles = \"low wealth\", \"high wealth\"\n",
    "    for (ax, w_idx, title) in zip(axes, w_indices, titles):\n",
    "\n",
    "        for i_y in y_idx:\n",
    "            for i_η in η_idx:\n",
    "                w, y, η = w_grid[w_idx], y_grid[i_y], η_grid[i_η]\n",
    "                H[i_y, i_η] = w_grid[σ_star[w_idx, i_y, i_η]] / (w + y)\n",
    "\n",
    "        cs1 = ax.contourf(y_grid, η_grid, np.transpose(H), alpha=0.5)\n",
    "\n",
    "        plt.colorbar(cs1, ax=ax) #, format=\"%.6f\")\n",
    "\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(r\"$y$\")\n",
    "        ax.set_ylabel(r\"$\\varepsilon$\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if savefig:\n",
    "        fig.savefig(figname)\n",
    "\n",
    "def plot_policies(savefig=False):\n",
    "    model = create_savings_model()\n",
    "    β, γ, η_grid, φ, w_grid, y_grid, Q = model\n",
    "    σ_star = mod_opi(model)\n",
    "    y_bar = floor(len(y_grid) / 2) # index of mid-point of y_grid\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.plot(w_grid, w_grid, \"k--\", label=r\"$45$\")\n",
    "\n",
    "    for (i, η) in enumerate(η_grid):\n",
    "        label = r\"$\\sigma^*$\" + \" at \" + r\"$\\eta = $\" + \"$η\"\n",
    "        ax.plot(w_grid, w_grid[σ_star[:, y_bar, i]], label=label)\n",
    "        \n",
    "    ax.legend()\n",
    "    if savefig:\n",
    "        fig.savefig(f\"../figures/modified_opt_saving_2.pdf\")\n",
    "\n",
    "def plot_time_series(m=2_000, savefig=False):\n",
    "\n",
    "    w_series = simulate_wealth(m)\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.plot(w_series, label=r\"w_t\")\n",
    "    ax.set_xlabel(\"time\")\n",
    "    ax.legend()\n",
    "    if savefig:\n",
    "        fig.savefig(\"../figures/modified_opt_saving_ts.pdf\")\n",
    "\n",
    "def plot_histogram(m=1_000_000, savefig=False):\n",
    "\n",
    "    w_series = simulate_wealth(m)\n",
    "    g = round(gini(w_series.sort()), ndigits=2)\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.hist(w_series, bins=40, density=True)\n",
    "    ax.set_xlabel(\"wealth\")\n",
    "    ax.text(15, 0.4, \"Gini = $g\")\n",
    "\n",
    "    if savefig:\n",
    "        fig.savefig(\"../figures/modified_opt_saving_hist.pdf\")\n",
    "\n",
    "def plot_lorenz(m=1_000_000, savefig=False):\n",
    "\n",
    "    w_series = simulate_wealth(m)\n",
    "    (F, L) = lorenz(w_series.sort())\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "    ax.plot(F, F, label=\"Lorenz curve, equality\")\n",
    "    ax.plot(F, L, label=\"Lorenz curve, wealth distribution\")\n",
    "    ax.legend()\n",
    "\n",
    "    if savefig:\n",
    "        fig.savefig(\"../figures/modified_opt_saving_lorenz.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6ef0b45",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_contours(savefig\u001b[38;5;241m=\u001b[39m\u001b[43mtrue\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'true' is not defined"
     ]
    }
   ],
   "source": [
    "plot_contours(savefig=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64d2d2a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_policies(savefig\u001b[38;5;241m=\u001b[39m\u001b[43mtrue\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'true' is not defined"
     ]
    }
   ],
   "source": [
    "plot_policies(savefig=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd2adad6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_time_series(savefig\u001b[38;5;241m=\u001b[39m\u001b[43mtrue\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'true' is not defined"
     ]
    }
   ],
   "source": [
    "plot_time_series(savefig=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b50dc00d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_histogram(savefig\u001b[38;5;241m=\u001b[39m\u001b[43mtrue\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'true' is not defined"
     ]
    }
   ],
   "source": [
    "plot_histogram(savefig=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ea7a8a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_lorenz(savefig\u001b[38;5;241m=\u001b[39m\u001b[43mtrue\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'true' is not defined"
     ]
    }
   ],
   "source": [
    "plot_lorenz(savefig=true)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "source_map": [
   10,
   30,
   160,
   164,
   166,
   168,
   231,
   233,
   286,
   288,
   469,
   473,
   477,
   481,
   485,
   487,
   489,
   739,
   743,
   747,
   749,
   751,
   925,
   929,
   933,
   935,
   937,
   1219,
   1223,
   1227,
   1231,
   1235
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}